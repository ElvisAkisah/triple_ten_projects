{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: solid #1e90ff 2px; padding: 15px; margin: 10px\">\n",
    "  <b>Overall Summary of the Project – Work Plan Review</b><br><br>\n",
    "\n",
    "  Hi <b>Elvis</b>, I’m <b>Victor Camargo</b> (<a href=\"https://hub.tripleten.com/u/e9cc9c11\" target=\"_blank\">profile</a>). I’ve reviewed your <b>code  work plan</b>.<br>\n",
    "\n",
    "  <b>Strong elements observed:</b><br>\n",
    "  ✔️ Good start inspecting the datasets (<code>head()</code>, <code>info()</code>, <code>isnull()</code>, <code>describe()</code>) — this ensures you understand data types and missing values early.<br>\n",
    "  ✔️ Correct decision to merge on <code>customerID</code> using a left join from <code>contract</code>, since it contains all clients.<br>\n",
    "  ✔️ Appropriate cleaning of <code>TotalCharges</code> (handling blanks → NaN → numeric) and rationale for filling with 0.<br>\n",
    "  ✔️ Well-defined churn target from <code>EndDate</code>, and thoughtful feature engineering with <code>tenure_months</code>.<br>\n",
    "  ✔️ Clear EDA plan (distribution of churn, contract type, services, charges/tenure, demographics).<br>\n",
    "  ✔️ Strong modeling path: Logistic Regression baseline → Random Forest → LightGBM with AUC-ROC as the main metric.<br><br>\n",
    "\n",
    "  <b>Suggestions to strengthen the work:</b><br>\n",
    "  • In your code, you repeated <code>print(df_contract.head())</code> when loading <code>df_personal</code> — update it to <code>df_personal.head()</code> so you actually preview the personal data.<br>\n",
    "  • Don’t forget to inspect <code>internet.csv</code> and <code>phone.csv</code> as well — right now, only <code>contract</code> and <code>personal</code> are checked.<br>\n",
    "  • When creating <code>tenure_months</code>, use the fixed reference date (<b>2020-02-01</b>) for active customers to avoid inconsistencies.<br>\n",
    "  • Make sure you exclude <code>EndDate</code> (after deriving churn) and any ID-like columns from features to prevent leakage.<br>\n",
    "  • Consider adding class imbalance handling methods explicitly (e.g., <code>class_weight</code> or upsampling on train set).<br><br>\n",
    "\n",
    "  <b>Final note:</b> Overall this is a solid plan and the code foundation is correct. Approved to move forward ✅ — just address the small fixes above (dataset preview typo, inspecting all four files, and leakage/imbalance guardrails). With those in place, you’ll be well-prepared for the solution phase.<br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\"><span style = \"font-size: 2em; font-weight: bold\"> SPRINT 17 - FINAL PROJECT </span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\"><span style = \"font-size: 1em; font-weight: bold\"> PROJECT TITLE : CLIENT CHURN PREDICTION FOR INTERCONNECT  </span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\"><span style = \"font-size: 2em; font-weight: bold\"> WORK PLAN  </span></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Loading and initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID   BeginDate              EndDate            Type  \\\n",
      "0  7590-VHVEG  2020-01-01                   No  Month-to-month   \n",
      "1  5575-GNVDE  2017-04-01                   No        One year   \n",
      "2  3668-QPYBK  2019-10-01  2019-12-01 00:00:00  Month-to-month   \n",
      "3  7795-CFOCW  2016-05-01                   No        One year   \n",
      "4  9237-HQITU  2019-09-01  2019-11-01 00:00:00  Month-to-month   \n",
      "\n",
      "  PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \n",
      "0              Yes           Electronic check           29.85        29.85  \n",
      "1               No               Mailed check           56.95       1889.5  \n",
      "2              Yes               Mailed check           53.85       108.15  \n",
      "3               No  Bank transfer (automatic)           42.30      1840.75  \n",
      "4              Yes           Electronic check           70.70       151.65  \n",
      "------------------------------------------------------------------------------------\n",
      "Data info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   BeginDate         7043 non-null   object \n",
      " 2   EndDate           7043 non-null   object \n",
      " 3   Type              7043 non-null   object \n",
      " 4   PaperlessBilling  7043 non-null   object \n",
      " 5   PaymentMethod     7043 non-null   object \n",
      " 6   MonthlyCharges    7043 non-null   float64\n",
      " 7   TotalCharges      7043 non-null   object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 440.3+ KB\n",
      "None\n",
      "------------------------------------------------------------------------------------\n",
      "missing Values count\n",
      "customerID          0\n",
      "BeginDate           0\n",
      "EndDate             0\n",
      "Type                0\n",
      "PaperlessBilling    0\n",
      "PaymentMethod       0\n",
      "MonthlyCharges      0\n",
      "TotalCharges        0\n",
      "dtype: int64\n",
      "------------------------------------------------------------------------------------\n",
      "Basic DEscriptive statistics\n",
      "       MonthlyCharges\n",
      "count     7043.000000\n",
      "mean        64.761692\n",
      "std         30.090047\n",
      "min         18.250000\n",
      "25%         35.500000\n",
      "50%         70.350000\n",
      "75%         89.850000\n",
      "max        118.750000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_contract = pd.read_csv('/datasets/final_provider/contract.csv')\n",
    "print(df_contract.head())\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Data info\")\n",
    "print(df_contract.info())\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"missing Values count\")\n",
    "print(df_contract.isnull().sum())\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Basic DEscriptive statistics\")\n",
    "print(df_contract.describe()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID   BeginDate              EndDate            Type  \\\n",
      "0  7590-VHVEG  2020-01-01                   No  Month-to-month   \n",
      "1  5575-GNVDE  2017-04-01                   No        One year   \n",
      "2  3668-QPYBK  2019-10-01  2019-12-01 00:00:00  Month-to-month   \n",
      "3  7795-CFOCW  2016-05-01                   No        One year   \n",
      "4  9237-HQITU  2019-09-01  2019-11-01 00:00:00  Month-to-month   \n",
      "\n",
      "  PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \n",
      "0              Yes           Electronic check           29.85        29.85  \n",
      "1               No               Mailed check           56.95       1889.5  \n",
      "2              Yes               Mailed check           53.85       108.15  \n",
      "3               No  Bank transfer (automatic)           42.30      1840.75  \n",
      "4              Yes           Electronic check           70.70       151.65  \n",
      "------------------------------------------------------------------------------------\n",
      "Data info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   customerID     7043 non-null   object\n",
      " 1   gender         7043 non-null   object\n",
      " 2   SeniorCitizen  7043 non-null   int64 \n",
      " 3   Partner        7043 non-null   object\n",
      " 4   Dependents     7043 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 275.2+ KB\n",
      "None\n",
      "------------------------------------------------------------------------------------\n",
      "missing Values count\n",
      "customerID       0\n",
      "gender           0\n",
      "SeniorCitizen    0\n",
      "Partner          0\n",
      "Dependents       0\n",
      "dtype: int64\n",
      "------------------------------------------------------------------------------------\n",
      "Basic DEscriptive statistics\n",
      "       SeniorCitizen\n",
      "count    7043.000000\n",
      "mean        0.162147\n",
      "std         0.368612\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         1.000000\n"
     ]
    }
   ],
   "source": [
    "df_personal = pd.read_csv('/datasets/final_provider/personal.csv')\n",
    "print(df_contract.head())\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Data info\")\n",
    "print(df_personal.info())\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"missing Values count\")\n",
    "print(df_personal.isnull().sum())\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "print(\"Basic DEscriptive statistics\")\n",
    "print(df_personal.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merging and Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Merge the four DataFrames (df_contract, df_personal, df_internet, df_phone) into a single, comprehensive DataFrame using customerID as the key.<br>\n",
    "\n",
    "We used a left merge, which ensures we keep all clients from the contract DataFrame, as it contains all customer IDs.\n",
    "  \n",
    "* Clean the TotalCharges column, converting it from a string to a numeric type and handling any missing values.<br>\n",
    "The column was a string because some entries were blank spaces. We converted these to NaNs and then filled them with 0. This is a reasonable approach because these missing values likely correspond to new customers who haven't accumulated any charges yet.\n",
    "  \n",
    "\n",
    "* Create the target feature, churn, which will be a binary column (0 or 1) based on the EndDate column.<br>\n",
    "\n",
    "We created a binary target variable (1 for churn, 0 for no churn) directly from the EndDate column. This is a crucial step for setting up our classification problem.\n",
    "  \n",
    "\n",
    "* Engineer new features, such as tenure (the duration of the client's contract), which is a crucial predictor for churn.<br>\n",
    "  The tenure_months feature is the client's total time with the company in months. For churned clients, this is the period from the BeginDate to the EndDate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis(EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analyze the Distribution of Churn: We'll start with a simple visualization to see how balanced or imbalanced our target variable is. This is crucial for understanding the challenge of our classification task.\n",
    "\n",
    "* Churn by Contract Type: We'll examine how the churn rate varies across different contract types (e.g., monthly, 1-year, 2-year). This will likely reveal a strong predictor of churn.\n",
    "\n",
    "* Impact of Services on Churn: We'll investigate if having certain services (like OnlineSecurity, TechSupport, or StreamingTV) affects the likelihood of a client churning.\n",
    "\n",
    "* Influence of Charges and Tenure: We'll use visualizations to see the relationship between TotalCharges, tenure_months, and MonthlyCharges with the Churn status. This will help us understand if there are financial or temporal patterns associated with churn.\n",
    "\n",
    "* Demographic Factors: We'll check if demographic data, such as gender, SeniorCitizen, Partner, and Dependents, plays a role in customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Categorical Feature Encoding:<br> We'll convert categorical text data (like Contract, PaymentMethod, etc.) into a numerical format. We'll use one-hot encoding for this, which creates new binary columns for each category.\n",
    "\n",
    "* Feature and Target Separation:<br> We'll split the data into two parts: the features (X), which are the columns we'll use to make predictions, and the target (y), which is our Churn variable.\n",
    "\n",
    "* Data Splitting:<br> We'll divide our dataset into three separate sets: a training set, a validation set, and a test set. This is essential for properly evaluating our model's performance and preventing overfitting.\n",
    "\n",
    "* Feature Scaling:<br> While not always necessary for tree-based models, it's good practice for others like logistic regression. We'll use StandardScaler to normalize the numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Initial Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select Models:<br> We'll use a few different types of classification algorithms to see which performs best on our data. A good starting point includes:\n",
    "\n",
    "* Logistic Regression:<br> A simple, fast, and highly interpretable model.\n",
    "\n",
    "* Random Forest Classifier:<br> An ensemble model known for its high performance and robustness.\n",
    "\n",
    "* LightGBM Classifier:<br> A powerful gradient boosting model that is very effective on tabular data and is known for its speed.\n",
    "\n",
    "* Initial Training and Evaluation:<br> We'll train each model on the training set and then evaluate its performance on the validation set. Our primary metric will be AUC-ROC, with Accuracy as an additional metric, as specified in the project requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
