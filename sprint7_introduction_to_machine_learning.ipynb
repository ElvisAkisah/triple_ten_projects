{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "<div style=\"border:solid green 2px; padding: 20px\"> <h1 style=\"color:green; margin-bottom:20px\">Reviewers comment v1</h1>\n\nHello Elvis!\n\nIm happy to review your project today \ud83d\ude4c\n\nYou can find my comments under the heading **\u00abReview\u00bb**. I will categorize my comments in green, blue or red boxes like this:\n\n<div class=\"alert alert-success\">\n    <b>Success:</b> if everything is done successfully\n</div>\n<div class=\"alert alert-warning\">\n    <b>Remarks:</b> if I can give some recommendations or ways to improve the project\n</div>\n<div class=\"alert alert-danger\">\n    <b>Needs fixing:</b> if the block requires some corrections. Work cant be accepted with the red comments\n</div>\n\nPlease dont remove my comments :) If you have any questions dont hesitate to respond to my comments in a different section. \n<div class=\"alert alert-info\"> <b>Student comments:</b> For example like this</div>    \n\n"}, {"cell_type": "markdown", "metadata": {}, "source": " <div style=\"border:solid green 2px; padding: 20px\">\n<b>Reviewer's comment v1:</b>\n    \n<b>Overall Feedback</b> \n    \n\nHello Elvis,\n\nAnother project successfully completed - well done! \ud83c\udfc6 Your consistent effort and progress are truly commendable.\n\nOur team is here to help you keep pushing forward and honing your skills as you advance through the program.\n\nYou\u2019ll find general comments below in the notebook in the `Reviewer's comment v1:` blocks.\n\n**What Was Great:**\n\n- Data Loading and Preparation: You successfully loaded the dataset and correctly separated the features and target variable. This is a crucial first step, and you handled it appropriately.\n- Model Training and Evaluation: Using a loop to train and evaluate each model is an efficient approach. You correctly used the accuracy_score metric to assess the models and identified the Random Forest classifier as the best-performing model.\n- Test Set Evaluation: You validated the performance of your selected model on a test set, ensuring that the model generalizes well to unseen data. The test accuracy being close to the validation accuracy is a good sign.\n   \n    \nCongratulations again on your accomplishment! Each project you complete adds to your growing expertise, and it\u2019s exciting to see you make such great strides. Keep up the great work! \ud83c\udfaf"}, {"cell_type": "markdown", "id": "f015269c-78fb-48e2-b458-3cdc5bfe0ced", "metadata": {}, "source": "# TRIPLETEN PROJECT SPRINT  7\n## Project Objectives\n\n* Develop a model for Megaline to classify subscribers.\n* Analyze behavior data for plan recommendations.\n* Maximize model accuracy for plan prediction."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment v1:</b>\n    \nGreat that you've added a short information about the project goal. It gives an overview of what you are going to achieve in this project.\n"}, {"cell_type": "code", "execution_count": 1, "id": "b306d021-e034-475e-8d03-e3cd243a62dd", "metadata": {"trusted": false}, "outputs": [], "source": "# importing required libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score"}, {"cell_type": "code", "execution_count": 2, "id": "f29d4402-e324-4bab-94e0-44890240c20e", "metadata": {"trusted": false}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>calls</th>\n      <th>minutes</th>\n      <th>messages</th>\n      <th>mb_used</th>\n      <th>is_ultra</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40.0</td>\n      <td>311.90</td>\n      <td>83.0</td>\n      <td>19915.42</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85.0</td>\n      <td>516.75</td>\n      <td>56.0</td>\n      <td>22696.96</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>77.0</td>\n      <td>467.66</td>\n      <td>86.0</td>\n      <td>21060.45</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106.0</td>\n      <td>745.53</td>\n      <td>81.0</td>\n      <td>8437.39</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>66.0</td>\n      <td>418.74</td>\n      <td>1.0</td>\n      <td>14502.75</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   calls  minutes  messages   mb_used  is_ultra\n0   40.0   311.90      83.0  19915.42         0\n1   85.0   516.75      56.0  22696.96         0\n2   77.0   467.66      86.0  21060.45         0\n3  106.0   745.53      81.0   8437.39         1\n4   66.0   418.74       1.0  14502.75         0"}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": "# Loading  the data\ndf = pd.read_csv('/datasets/users_behavior.csv')\ndf.head()"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment v0</b>\n    \nHere you have a path to your local dataset which will not work in the Tripleten environment. Correct path to the file is the following: `/datasets/users_behavior.csv`\n\nYou can adjust your try/except structure with different paths so it will work everywhere.\n    \nAlso, I recommend that you always run your project once more on the TripleTen platform before submitting your work to avoid possible errors. You can do this by selecting `Kernel -> Restart & Run All`."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-info\"> <b>Student comments V0:</b> Thanks, I have used the required path,restarted and ran ALL</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment v1:</b>\n    \n\ud83d\udc4f"}, {"cell_type": "code", "execution_count": 3, "id": "c1082dc9-3601-4fea-a7e9-6fa68a9aae12", "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3214 entries, 0 to 3213\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   calls     3214 non-null   float64\n 1   minutes   3214 non-null   float64\n 2   messages  3214 non-null   float64\n 3   mb_used   3214 non-null   float64\n 4   is_ultra  3214 non-null   int64  \ndtypes: float64(4), int64(1)\nmemory usage: 125.7 KB\n"}], "source": "df.info()"}, {"cell_type": "markdown", "id": "4fed3b9d-1472-4d45-9ad6-b8ba7ab0c72c", "metadata": {}, "source": "**From the above data info, there are no missing values**"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment v1:</b>\n    \nWell done! Data have been successfully loaded and inspected."}, {"cell_type": "markdown", "id": "3b0d3842-e752-4d25-ad1e-23b3f5ab3b54", "metadata": {}, "source": "**2. Spliting the Source Data**\n\n**I will split the data into training, validation, and test sets in the ratio 3:1:1**"}, {"cell_type": "code", "execution_count": 4, "id": "52ec33b9-e914-4e64-aed7-4ce1d8a6790d", "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Training set size: 1928\nValidation set size: 643\nTest set size: 643\n"}], "source": "# Separate features and target\nfeatures = df.drop('is_ultra', axis=1)\ntarget = df['is_ultra']\n\n# Split into training, validation, and test sets\nfeatures_train, features_test, target_train, target_test = train_test_split(\n    features, target, test_size=0.2, random_state=12345\n)\n\nfeatures_train, features_valid, target_train, target_valid = train_test_split(\n    features_train, target_train, test_size=0.25, random_state=12345\n)\n\n# Check the sizes of the resulting datasets\nprint(\"Training set size:\", len(features_train))\nprint(\"Validation set size:\", len(features_valid))\nprint(\"Test set size:\", len(features_test))"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-warning\">\n<b>Reviewer's comment v1:</b>\n    \nConsider using stratified splits (`stratify` parameter) to ensure that class distributions are similar across training, validation, and test sets.\n\n"}, {"cell_type": "markdown", "id": "5f6c46fa-6a71-43fd-81b6-3686e35835c3", "metadata": {}, "source": "**3. Investigate the Quality of Different Models**\n"}, {"cell_type": "code", "execution_count": 5, "id": "a339d229-bba3-4a64-85f1-99441285797e", "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Best Decision Tree Accuracy: 0.7744945567651633, Depth: 7\nBest Random Forest Accuracy: 0.7947122861586314, Estimators: 50\nLogistic Regression Accuracy: 0.7293934681181959\n"}], "source": "# Decision Tree\nbest_tree_accuracy = 0\nbest_tree_depth = 0\nfor depth in range(1, 11):\n    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n    model.fit(features_train, target_train)\n    predictions_valid = model.predict(features_valid)\n    accuracy = accuracy_score(target_valid, predictions_valid)\n    if accuracy > best_tree_accuracy:\n        best_tree_accuracy = accuracy\n        best_tree_depth = depth\n\nprint(f\"Best Decision Tree Accuracy: {best_tree_accuracy}, Depth: {best_tree_depth}\")\n\n# Random Forest\nbest_forest_accuracy = 0\nbest_forest_est = 0\nfor est in range(10, 51, 10):\n    model = RandomForestClassifier(random_state=12345, n_estimators=est)\n    model.fit(features_train, target_train)\n    predictions_valid = model.predict(features_valid)\n    accuracy = accuracy_score(target_valid, predictions_valid)\n    if accuracy > best_forest_accuracy:\n        best_forest_accuracy = accuracy\n        best_forest_est = est\n\nprint(f\"Best Random Forest Accuracy: {best_forest_accuracy}, Estimators: {best_forest_est}\")\n\n# Logistic Regression\nmodel = LogisticRegression(random_state=12345, solver='liblinear')\nmodel.fit(features_train, target_train)\npredictions_valid = model.predict(features_valid)\nlogistic_accuracy = accuracy_score(target_valid, predictions_valid)\n\nprint(f\"Logistic Regression Accuracy: {logistic_accuracy}\")"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment v1:</b>\n    \nEverything is correct here! Great that you've managed to check multiple models. \n\nSome possible minor improvements: \n\n- If you find yourself repeating similar blocks of code, consider writing a function. This will make your code more organized and easier to maintain.\n- Besides accuracy, consider evaluating models using additional metrics like F1-score, precision, recall, or the ROC-AUC score for a more holistic view of performance, especially if the class distribution is imbalanced.\n- Consider using GridSearchCV or RandomizedSearchCV from sklearn.model_selection for a more systematic hyperparameter search."}, {"cell_type": "markdown", "id": "f0899f42-4c46-428c-a3d3-eeff8e256064", "metadata": {}, "source": "**Findings:**\n\n* Decision Tree: The accuracy varied with the max_depth. We found the best depth that maximized accuracy on the validation set.\n* Random Forest: The accuracy also varied with the number of n_estimators. We found the optimal number of trees.\n* Logistic Regression: Achieved a certain accuracy without hyperparameter tuning, but may not be the optimal model."}, {"cell_type": "markdown", "id": "7f247cb8-6526-4a05-b822-a2c577823466", "metadata": {}, "source": "**4. Check the Quality of the Model Using the Test Set**"}, {"cell_type": "code", "execution_count": 6, "id": "a7367aad-7664-4186-a04e-b6aa0a8b8fac", "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Test Accuracy of the Best Model: 0.7807153965785381\n"}], "source": "# Select the best model (based on validation accuracy)\nif best_forest_accuracy > best_tree_accuracy and best_forest_accuracy > logistic_accuracy:\n    best_model = RandomForestClassifier(random_state=12345, n_estimators=best_forest_est)\nelif best_tree_accuracy > logistic_accuracy:\n    best_model = DecisionTreeClassifier(random_state=12345, max_depth=best_tree_depth)\nelse:\n    best_model = LogisticRegression(random_state=12345, solver='liblinear')\n\n# Train the best model on the combined training and validation sets\nfeatures_train_full = pd.concat([features_train, features_valid])\ntarget_train_full = pd.concat([target_train, target_valid])\n\nbest_model.fit(features_train_full, target_train_full)\n\n# Make predictions on the test set\npredictions_test = best_model.predict(features_test)\n\n# Calculate the test accuracy\ntest_accuracy = accuracy_score(target_test, predictions_test)\n\nprint(f\"Test Accuracy of the Best Model: {test_accuracy}\")"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment v1:</b>\n    \nGreat! Well above the required threshold. "}, {"cell_type": "markdown", "id": "a932d099-acb3-4dda-b2e9-4eec921da866", "metadata": {}, "source": "**5. Additional Task: Sanity Check the Model**"}, {"cell_type": "code", "execution_count": 7, "id": "031e86bf-7a70-4225-8d27-7c81702d78b0", "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Baseline Accuracy (Most Frequent Class): 0.6951788491446346\nModel performs better than the baseline.\n"}], "source": "# Baseline: Predict the most frequent class\nfrom sklearn.dummy import DummyClassifier\n\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_clf.fit(features_train_full, target_train_full)\ndummy_predictions = dummy_clf.predict(features_test)\ndummy_accuracy = accuracy_score(target_test, dummy_predictions)\n\nprint(f\"Baseline Accuracy (Most Frequent Class): {dummy_accuracy}\")\n\nif test_accuracy > dummy_accuracy:\n    print(\"Model performs better than the baseline.\")\nelse:\n    print(\"Model does not perform better than the baseline.\")"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment v1:</b>\n    \nEverything is correct here. "}, {"cell_type": "markdown", "id": "16e1a7dc-d9cc-46fc-aae9-705722afc91c", "metadata": {}, "source": "# Conclusion\n**A Random Forest model, with optimized hyperparameters, achieved 78.07% accuracy in predicting Megaline's mobile plan recommendations, exceeding the 75% threshold and outperforming a baseline, making it suitable for deployment.**\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-success\">\n<b>Reviewer's comment v1:</b>\n    \n\nGreat job on your overall conclusions and recommendations!  Your recommendations are well-thought and could be very valuable to the business."}], "metadata": {"ExecuteTimeLog": [{"duration": 803, "start_time": "2025-03-25T09:26:35.243Z"}, {"duration": 565, "start_time": "2025-03-25T09:26:36.048Z"}, {"duration": 0, "start_time": "2025-03-25T09:26:36.615Z"}, {"duration": 0, "start_time": "2025-03-25T09:26:36.617Z"}, {"duration": 0, "start_time": "2025-03-25T09:26:36.623Z"}, {"duration": 0, "start_time": "2025-03-25T09:26:36.624Z"}, {"duration": 0, "start_time": "2025-03-25T09:26:36.625Z"}, {"duration": 190, "start_time": "2025-03-25T21:23:29.535Z"}, {"duration": 792, "start_time": "2025-03-25T21:23:51.379Z"}, {"duration": 29, "start_time": "2025-03-25T21:23:52.173Z"}, {"duration": 10, "start_time": "2025-03-25T21:23:52.204Z"}, {"duration": 6, "start_time": "2025-03-25T21:23:52.217Z"}, {"duration": 575, "start_time": "2025-03-25T21:23:52.225Z"}, {"duration": 209, "start_time": "2025-03-25T21:23:52.803Z"}, {"duration": 5, "start_time": "2025-03-25T21:23:53.014Z"}, {"duration": 745, "start_time": "2025-03-25T21:26:55.485Z"}, {"duration": 17, "start_time": "2025-03-25T21:26:56.233Z"}, {"duration": 9, "start_time": "2025-03-25T21:26:56.251Z"}, {"duration": 7, "start_time": "2025-03-25T21:26:56.262Z"}, {"duration": 591, "start_time": "2025-03-25T21:26:56.271Z"}, {"duration": 215, "start_time": "2025-03-25T21:26:56.864Z"}, {"duration": 5, "start_time": "2025-03-25T21:26:57.081Z"}, {"duration": 773, "start_time": "2025-03-25T22:03:48.189Z"}, {"duration": 29, "start_time": "2025-03-25T22:03:48.965Z"}, {"duration": 9, "start_time": "2025-03-25T22:03:48.996Z"}, {"duration": 13, "start_time": "2025-03-25T22:03:49.006Z"}, {"duration": 563, "start_time": "2025-03-25T22:03:49.021Z"}, {"duration": 214, "start_time": "2025-03-25T22:03:49.586Z"}, {"duration": 11, "start_time": "2025-03-25T22:03:49.802Z"}], "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}