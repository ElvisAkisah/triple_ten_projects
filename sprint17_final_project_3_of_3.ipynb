{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <h1 align = \"center\"><span style = \"font-size: 2em; font-weight: bold\"> SPRINT 17 - FINAL PROJECT </span></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\"><span style = \"font-size: 1em; font-weight: bold\"> PROJECT TITLE : CLIENT CHURN PREDICTION FOR INTERCONNECT  </span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\"><span style = \"font-size: 2em; font-weight: bold\"> SOLUTION REPORT   </span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project Solution Report</h1>\n",
    "<hr>\n",
    "\n",
    "<p>All key steps of the original work plan were performed. No essential steps were skipped.</p>\n",
    "<ul>\n",
    "    <li><b>Data Loading and Initial Exploration:</b> I loaded all four datasets (<code>contract.csv</code>, <code>personal.csv</code>, <code>internet.csv</code>, <code>phone.csv</code>) and performed a thorough initial inspection.</li>\n",
    "    <li><b>Data Merging and Feature Engineering:</b> The datasets were merged into a single DataFrame. I cleaned the <code>TotalCharges</code> column, engineered a <code>tenure_months</code> feature, and created the binary <code>Churn</code> target variable.</li>\n",
    "    <li><b>Exploratory Data Analysis (EDA):</b> I performed extensive data visualization to understand the relationships between features and churn, identifying key drivers like contract type, tenure, and monthly charges.</li>\n",
    "    <li><b>Data Preprocessing:</b> I prepared the data for modeling by one-hot encoding categorical features, scaling numerical features, and splitting the dataset into training, validation, and test sets. We also incorporated a strategy for handling class imbalance.</li>\n",
    "    <li><b>Model Selection and Training:</b> I trained and evaluated three different models (Logistic Regression, Random Forest, and LightGBM) on the validation set to select the best performer.</li>\n",
    "    <li><b>Final Model Evaluation:</b> The best-performing model was retrained on the combined training and validation sets and evaluated on the final, unseen test set to report the ultimate performance.</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p>The primary difficulty encountered was <b>data access</b>. The specified data folder path (<code>/datasets/final_provider/</code>) was not accessible in the environment, which prevented the code from running and halted progress.</p>\n",
    "<ul>\n",
    "    <li><b>Solution:</b> I addressed this by first providing code to check for the correct data path. When that didn't work, we made the file path a variable in the code and instructed the user to update it with their local path. This allowed the project to proceed regardless of the execution environment.</li>\n",
    "</ul>\n",
    "<p>Another minor challenge was the <b>data cleaning and feature engineering</b> step. The <code>TotalCharges</code> column was initially an <code>object</code> type due to spaces, and the <code>tenure_months</code> feature required careful calculation to use a consistent reference date for active clients. These were solved by using <code>pd.to_numeric</code> with the <code>errors='coerce'</code> argument and applying conditional logic (<code>np.where</code>) to handle both churned and non-churned clients.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p>The most critical steps were:</p>\n",
    "<ul>\n",
    "    <li><b>Rigorous Data Preparation:</b> Correctly <b>merging</b> the four separate datasets was essential. Handling the non-numeric values in <code>TotalCharges</code> and creating the <code>Churn</code> target variable were foundational.</li>\n",
    "    <li><b>Feature Engineering:</b> Engineering the <b><code>tenure_months</code></b> feature was a key step. The EDA showed that tenure is one of the most significant predictors of churn, and creating this feature allowed our models to use this crucial information.</li>\n",
    "    <li><b>Addressing Class Imbalance:</b> The initial EDA revealed a class imbalance, which can lead to biased models. By explicitly handling this with the <code>class_weight='balanced'</code> parameter in our models, we ensured that the model would not simply predict the majority class, leading to a more reliable classifier.</li>\n",
    "    <li><b>Proper Evaluation Strategy:</b> Splitting the data into <b>training, validation, and test sets</b> was fundamental. This process ensured that our final reported scores were an unbiased measure of the model's performance on unseen data.</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p>The final model is a <b>LightGBM Classifier</b>.</p>\n",
    "<p>Its final quality scores on the unseen test set are:</p>\n",
    "<ul>\n",
    "    <li><b>AUC-ROC:</b> <b>0.8334</b></li>\n",
    "    <li><b>Accuracy:</b> <b>0.7544</b></li>\n",
    "</ul>\n",
    "<p>This AUC-ROC score places the model in the <b>0.81 â‰¤ AUC-ROC < 0.85</b> range, which earns a score of <b>4.5 SP</b> based on the project criteria.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
